% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pmed_get_data.R
\name{pmed_get_data}
\alias{pmed_get_data}
\title{Aggregate and Process News Articles Based on a Search Query}
\usage{
pmed_get_data(
  pmids,
  task_type = c("pubtations", "icites", "affiliations", "pubmed", "pmc"),
  cores = 3,
  ncbi_key = NULL
)
}
\arguments{
\item{x}{A string containing the URL of the website to be scraped.}
}
\value{
A data frame with columns 'url', 'type', and 'text', containing the URL,
        type of HTML node, and the extracted text, respectively. Returns an empty
        data frame with these columns if scraping fails.
}
\description{
This function serves as the primary interface for aggregating news data.
It first builds an RSS feed URL based on a given search query, then parses
the RSS feed to extract news articles. Each article is then scraped and processed
to produce a consolidated dataset containing the article contents along with
associated metadata.
}
\examples{
get_site("http://example.com")
}
